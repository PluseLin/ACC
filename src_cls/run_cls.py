import os
import sys
import logging
import collections

from dataclasses import dataclass, field
from typing import Optional, Tuple, List, Union, Dict, Any
import glob

import torch
import numpy as np
import torch.nn as nn
import re
from torch.nn import CrossEntropyLoss

import transformers
from transformers import (
    DataCollatorForSeq2Seq,
    HfArgumentParser,
    PreTrainedTokenizerFast,
    TrainingArguments,
    set_seed,
)

from torch.utils.data.distributed import DistributedSampler


from transformers import AdamW, get_linear_schedule_with_warmup
from tqdm import trange,tqdm

from util_cls import *
from modeling_cls import *

logger = logging.getLogger(__name__)

WEIGHTS_NAME = "pytorch_model.bin"

MODELS={
    "roberta_duma":(RobertaConfig,RobertaTokenizerFast,RobertaDUMASpanClassifier),
    "roberta_binary":(RobertaConfig,RobertaTokenizerFast,RobertaDUMASpanClassifier),
    "roberta_sc":(RobertaConfig,RobertaTokenizerFast,RobertaSpanClassfier),
    "roberta_vanilla":(RobertaConfig,RobertaTokenizerFast,RobertaForSequenceClassification),
    "bert":(BertConfig,BertTokenizerFast,BertDUMASpanClassifier)
}

@dataclass
class ModelArguments:
    """
    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.
    """

    model_name_or_path: str = field(
        metadata={"help": "Path to pretrained model or model identifier from huggingface.co/models"}
    )
    model_type: str = field(

    )
    config_name: Optional[str] = field(
        default=None, metadata={"help": "Pretrained config name or path if not the same as model_name"}
    )
    tokenizer_name: Optional[str] = field(
        default=None, metadata={"help": "Pretrained tokenizer name or path if not the same as model_name"}
    )
    cache_dir: Optional[str] = field(
        default=None,
        metadata={"help": "Where do you want to store the pretrained models downloaded from huggingface.co"},
    )
    model_revision: str = field(
        default="main",
        metadata={"help": "The specific model version to use (can be a branch name, tag name or commit id)."},
    )
    use_auth_token: bool = field(default=False)
    use_vanilla:bool =field(default=False)

@dataclass
class DataTrainingArguments:
    """
    Arguments pertaining to what data we are going to input our model for training and eval.
    """

    task_name: Optional[str] = field(default="ner", metadata={"help": "The name of the task (ner, pos...)."})
    data_dir: Optional[str] = field(
        default=None, metadata={"help": "The dir of the dataset to use."}
    )
    train_file: Optional[str] = field(
        default='train.json', metadata={"help": "The dir of the dataset to use."}
    )
    question_column_name: Optional[str] = field(
        default='question', metadata={"help": "The column name of text to input in the file (a csv or JSON file)."}
    )
    context_column_name: Optional[str] = field(
        default='context', metadata={"help": "The column name of text to input in the file (a csv or JSON file)."}
    )
    label_column_name: Optional[str] = field(
        default='label', metadata={"help": "The column name of label to input in the file (a csv or JSON file)."}
    )
    overwrite_cache: bool = field(
        default=False, metadata={"help": "Overwrite the cached training and evaluation sets"}
    )
    preprocessing_num_workers: Optional[int] = field(
        default=None,
        metadata={"help": "The number of processes to use for the preprocessing."},
    )
    max_num_span: int = field(
        default=None,
    )
    max_seq_length: int = field(
        default=None,
        metadata={
            "help": "The maximum total input sequence length after tokenization. If set, sequences longer "
            "than this will be truncated, sequences shorter will be padded."
        },
    )
    doc_stride: int = field(
        default=128,
    )
    label_all_tokens: bool = field(
        default=False,
        metadata={
            "help": "Whether to put the label for one word on all tokens of generated by that word or just on the "
            "one (in which case the other tokens will have a padding index)."
        },
    )
    save_embeds: bool = field(
        default=False,
    )
    return_entity_level_metrics: bool = field(
        default=False,
        metadata={"help": "Whether to return all the entity levels during evaluation or just the overall ones."},
    )
    max_train_samples: Optional[int] = field(
        default=None,
    )
    max_eval_samples: Optional[int] = field(
        default=None,
    )
    max_predict_samples: Optional[int] = field(
        default=None,
    )
    pad_to_max_length: bool = field(
        default=False,
        metadata={
            "help": "Whether to pad all samples to model maximum sentence length. "
            "If False, will pad the samples dynamically when batching to the maximum length in the batch. More "
            "efficient on GPU but very bad for TPU."
        },
    )
    do_debug:bool =field(
        default=False,
    )

def train(args,dataset,eval_datasets,eval_examples,model,tokenizer):
    """ Train the model """
    train_sampler = RandomSampler(dataset)
    train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=args.per_device_train_batch_size)

    if args.max_steps > 0:
        t_total = args.max_steps
        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1
    else:
        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs

    # Prepare optimizer and schedule (linear warmup and decay)
    no_decay = ['bias', 'LayerNorm.weight']
    optimizer_grouped_parameters = [
        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},
        # {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}
        ]
    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)

    # multi-gpu training (should be after apex fp16 initialization)
    if args.n_gpu > 1:
        model = torch.nn.DataParallel(model)

    # Train!
    print("***** Running training *****")
    print(f"  Num examples = {len(dataset)}")
    print(f"  Num Epochs = {args.num_train_epochs}")
    print(f"  Instantaneous batch size per GPU = {args.per_gpu_train_batch_size}")
    print(f"  Total train batch size (w. parallel, distributed & accumulation) = {args.per_device_train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1)}",)
    print(f"  Gradient Accumulation steps = {args.gradient_accumulation_steps}")
    print(f"  Total optimization steps = {t_total}")

    global_step = 0
    tr_loss, logging_loss = 0.0, 0.0
    best_steps = 0
    best_acc=-1.0
    model.zero_grad()
    # train_iterator = range(int(args.num_train_epochs), desc="Epoch", disable=args.local_rank not in [-1, 0])
    train_iterator = trange(int(args.num_train_epochs))
    for i in train_iterator:
        print("epoch:", i)
        for step, batch in enumerate(train_dataloader):
            model.train()
            batch = tuple(t.to(args.device) for t in batch)

            if isinstance(model,RobertaDUMASpanClassifier) or isinstance(model,BertDUMASpanClassifier):
                inputs={
                    "input_ids":batch[0],
                    "attention_mask":batch[1],
                    "token_type_ids":batch[2],
                    "labels":batch[3],
                    "p_ranges":batch[4],
                    "q_ranges":batch[5],
                }

            elif isinstance(model,RobertaSpanClassfier):
                inputs={
                    "input_ids":batch[0],
                    "attention_mask":batch[1],
                    "token_type_ids":batch[2],
                    "labels":batch[3],
                    "q_ranges":batch[5],
                    "a_ranges":batch[6],
                }

            else:
                inputs={
                    "input_ids":batch[0],
                    "attention_mask":batch[1],
                    "token_type_ids":batch[2],
                    "labels":batch[3]
                }
            outputs = model(**inputs)
            loss = outputs.loss  # model outputs are always tuple in transformers (see doc)
            
            # input()

            if args.n_gpu > 1:
                loss = loss.mean() # mean() to average on multi-gpu parallel training
            if args.gradient_accumulation_steps > 1:
                loss = loss / args.gradient_accumulation_steps

            if args.fp16:
                optimizer.backward(loss)
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)
            else:
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)

            tr_loss += loss.item()
            if (step + 1) % args.gradient_accumulation_steps == 0:

                optimizer.step()
                scheduler.step()  # Update learning rate schedule
                model.zero_grad()
                global_step += 1

            if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step>0 and global_step % args.logging_steps == 0:
                print(f"Average loss: {str((tr_loss - logging_loss)/args.logging_steps)} at global step: {str(global_step)}\n")
                logging_loss = tr_loss

            if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step>0 and global_step % args.save_steps == 0:
                # evaluate checkpoint
                metrics,_=eval(args,eval_datasets,eval_examples,model,prefix="")
                print(f"step:{global_step} ,acc:{metrics['acc']}\n")
                if metrics["acc"]>best_acc:
                    best_steps=global_step
                    # Save model checkpoint
                    output_dir = os.path.join(args.output_dir, 'checkpoint-best')
                    if not os.path.exists(output_dir):
                        os.makedirs(output_dir)
                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training
                    model_to_save.save_pretrained(output_dir)
                    tokenizer.save_vocabulary(output_dir)
                    torch.save(args, os.path.join(output_dir, WEIGHTS_NAME))
                    best_acc=metrics["acc"]
                    print(f"Saving model checkpoint to {output_dir}")

                    with open(os.path.join(args.output_dir,"dev_results.json"),"w",encoding="utf-8",newline="") as f:
                        json.dump(metrics,f,indent=4,ensure_ascii=False)

            if args.max_steps > 0 and global_step > args.max_steps:
                break

        if args.max_steps > 0 and global_step > args.max_steps:
            # train_iterator.close()
            break

    return global_step, tr_loss / global_step, best_steps

def eval(training_args,dataset,examples,model,prefix,do_predict=False):

    if not os.path.exists(training_args.output_dir) and training_args.local_rank in [-1, 0]:
        os.makedirs(training_args.output_dir)



    eval_batch_size = training_args.per_device_eval_batch_size
    # Note that DistributedSampler samples randomly
    eval_sampler = SequentialSampler(dataset) if training_args.local_rank == -1 else DistributedSampler(dataset)
    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=eval_batch_size)

    # Eval!
    print(f"***** Running evaluation {prefix} *****")
    print(f"  Num examples = {len(dataset)}")
    print(f"  Batch size = {eval_batch_size}")


    predictions_dir=os.path.join(training_args.output_dir,"predictions")
    os.mkdir(predictions_dir) if not os.path.exists(predictions_dir) else None

    predicts=[]
    labels=[]

    # for batch in tqdm(eval_dataloader, desc="Evaluating"):
    model.eval()
    with torch.no_grad():
        for batch in eval_dataloader:
            batch = tuple(t.to(training_args.device) for t in batch)

            if isinstance(model,RobertaDUMASpanClassifier) or isinstance(model,BertDUMASpanClassifier):
                inputs={
                    "input_ids":batch[0],
                    "attention_mask":batch[1],
                    "token_type_ids":batch[2],
                    "p_ranges":batch[4],
                    "q_ranges":batch[5],
                }
            
            elif isinstance(model,RobertaSpanClassfier):
                    inputs={
                        "input_ids":batch[0],
                        "attention_mask":batch[1],
                        "token_type_ids":batch[2],
                        # "labels":batch[3],
                        "q_ranges":batch[5],
                        "a_ranges":batch[6],
                    }

            else:
                inputs={
                    "input_ids":batch[0],
                    "attention_mask":batch[1],
                    "token_type_ids":batch[2],
                    # "labels":batch[3]
                }

            outputs = model(**inputs)
            predicts+=to_list(torch.argmax(outputs.logits,dim=-1))
            if not do_predict:
                labels+=to_list(batch[3])

    if not do_predict:
        metrics=compute_metrics(
            predicts,
            labels
        )

    else:
        metrics=None
    
    all_predictions=[]

    for pred,label,example in zip(predicts,labels,examples):
        all_predictions.append(
            [example.example_id,pred,label]
        )

    prediction_file=os.path.join(predictions_dir,"eval-predictions.json") if not do_predict else os.path.join(predictions_dir,"eval-predictions.json")

    with open(prediction_file,"w",encoding="utf-8",newline="") as f:
        json.dump(all_predictions,f,indent=4,ensure_ascii=False) 

    model.train()
    return metrics,all_predictions

def main():
    # We now keep distinct sets of args, for a cleaner separation of concerns.
    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()

    # Setup logging
    logging.basicConfig(
        format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
        datefmt="%m/%d/%Y %H:%M:%S",
        handlers=[logging.StreamHandler(sys.stdout)],
    )

    log_level = training_args.get_process_log_level()
    logger.setLevel(log_level)
    transformers.utils.logging.set_verbosity(log_level)
    transformers.utils.logging.enable_default_handler()
    transformers.utils.logging.enable_explicit_format()

    training_args.local_rank=-1

    # Log on each process the small summary:
    logger.warning(
        f"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}, "
        + f"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}"
    )
    print(f"Training/evaluation parameters {training_args}")

    set_seed(training_args.seed)

    # Load Models

    model_type=model_args.model_type

    if model_args.use_vanilla:
        model_type+="_vanilla"

    config_class, tokenizer_class, model_class = MODELS[model_type]

    config=config_class.from_pretrained(
        model_args.config_name if model_args.config_name else model_args.model_name_or_path,
        cache_dir=model_args.cache_dir,
        revision=model_args.model_revision,
        use_auth_token=True if model_args.use_auth_token else None,
    )

    config.num_labels=3 if not "binary" in model_args.model_type else 2

    tokenizer_name_or_path = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path

    tokenizer=tokenizer_class.from_pretrained(
        tokenizer_name_or_path,
        cache_dir=model_args.cache_dir,
        use_fast=True,
        revision=model_args.model_revision,
        use_auth_token=True if model_args.use_auth_token else None,
        add_prefix_space=True,
    )

    model=model_class.from_pretrained(
        model_args.model_name_or_path,
        config=config,
        cache_dir=model_args.cache_dir,
    )
    model.to(training_args.device)
    # Load Datasets

    if training_args.do_train:
        train_datasets,_=load_datasets(model_args,data_args,data_args.task_name,tokenizer,prefix="train",debug=data_args.do_debug)
        eval_datasets,eval_examples=load_datasets(model_args,data_args,data_args.task_name,tokenizer,prefix="dev",debug=data_args.do_debug)
        global_step, tr_loss, best_steps = train(training_args, train_datasets, eval_datasets,eval_examples, model, tokenizer)
        print(f" global_step = {global_step}, average loss = {tr_loss}, best_steps = {best_steps}" )

    best_checkpoint=None
    best_acc=-1.00

    if training_args.do_eval:
        eval_datasets,eval_examples=load_datasets(model_args,data_args,data_args.task_name,tokenizer,prefix="dev",debug=data_args.do_debug)
        print(training_args.output_dir)
        # checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(training_args.output_dir + '/**/' + WEIGHTS_NAME, recursive=True), key=lambda x: int(
        #     re.findall(".*checkpoint-(.*)/.*", x)[0] if len(re.findall(".*checkpoint-(.*)/.*", x)) > 0 else 0)))
        checkpoints=[os.path.join(training_args.output_dir,"checkpoint-best")]
        logging.getLogger("transformers.modeling_utils").setLevel(logging.WARN)  # Reduce logging
        print("Evaluate the following checkpoints: %s", checkpoints)
        all_metrics=[]
        for checkpoint in checkpoints:
            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else ""
            prefix = checkpoint.split('/')[-1] if checkpoint.find('checkpoint') != -1 else ""
            
            model = model_class.from_pretrained(checkpoint)
            model.to(training_args.device)
            metrics,predictions = eval(training_args, eval_datasets, eval_examples ,model, prefix=prefix, do_predict=False)
            all_metrics.append([checkpoint,metrics])
        
        with open(os.path.join(training_args.output_dir,"dev_results.json"),"w",encoding="utf-8",newline="") as f:
            data={}
            for (checkpoint,metric) in all_metrics:
                data[checkpoint]=metric
                if metric["acc"]>best_acc:
                    best_acc=metric["acc"]
                    best_checkpoint=checkpoint
            json.dump(data,f,indent=4,ensure_ascii=False)
        print(f"best acc:{best_acc}")

if __name__=="__main__":
    main()